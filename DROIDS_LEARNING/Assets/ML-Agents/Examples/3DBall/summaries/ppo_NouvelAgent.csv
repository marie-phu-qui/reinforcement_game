Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length
1000,1.4189383,0.00029700302,0.1930794,1.0837208808854568,1.0837209612824197,21.813953488372093
2000,1.4189383,0.00029100303,0.22631118,1.1418604434922683,1.141860497032487,22.41860465116279
3000,1.4189383,0.000285003,0.19268969,1.1904761706079756,1.1904762231168293,22.904761904761905
4000,1.4189383,0.00027900303,0.23563947,1.0199999756283231,1.0200000301003456,21.2
5000,1.4189383,0.00027300304,0.12940523,0.9695652205011119,0.9695652467401131,20.695652173913043
6000,1.4189383,0.00026700302,0.1552645,1.1714285640489488,1.1714286037853785,22.714285714285715
